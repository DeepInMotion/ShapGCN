# Log dir
logs:
  dir: logs/${dataset}_

# Experiment name under which the run is stored
experiment: class_5_vis

# for continuing training put path here and true
cont_training: False
cont_dir: './logs/1008_xview60/2023-11-20 08-46-56'

# mode
mode: nas

# Env. setting
ddp: False
gpus: [0]
seed: 1234
num_threads: 16
report_freq: 5
no_progress_bar: False
mmap: True
work_dir: /

# Old SP (True) or new (False)
old_sp: False

# ------ Data settings ------------
# xsub60, xview60, xsub120, xsetup120, kinetics, cp
dataset: xview60
dataset_args:
  layout: ntu # ntu -> 300 frames; kinetics 400 frames
  strategy: distance
  num_frame: 150
  inputs: JVBA
  transform: True # set to True if dataset == xview60!
  normalize: False
  root_folder: /data/npy_files
  ntu60_path: /data/raw/ntu/ntu60
  ntu120_path: /data/raw/ntu/ntu120
  filter: True
  filter_order: 8

# Dataloader settings
batch_size: 16
num_workers: 12
pin_memory: True
num_frame: 288
shuffle: True

# Controller args
use_baseline:   False
reward_map_fn:  None
train_epochs:   20
warmup_rollouts: 20
warmup_epochs: 0
argmax_epochs:  80
rollouts:       20
eval_interval: 5
max_iter: 50

# XAI
xai_model_path: "xai/argmax_1001_xview/student_model_1001.pth.tar"
xai_algo: gradcam # gradcam or shap
xai_method: gradcam  # shap:[shap, perturb, perturb_shap, vis]; gradcam:[gradcam, cam, perturb, vis]
xai_hyper_param: [2, 2, 0, 0, 0]
xai_num_back: 20
xai_random_back: True
xai_back_idx: 1
xai_back_seed: 123
xai_batch_size: 16

# RETRAIN -> use this for builidng and retraining an architecture to not run the full NAS
# put in architectrue and hyperparameter choices as arrays
retrain_arch_param: [1, 1, 3, 4, 0, 0, 0, 0, 1, 0, 2, 3, 2, 2, 0, 0, 0, 1, 2, 0]
retrain_hyper_param: [2, 2, 0, 0, 0]

# policy deletion
policy_deletion: False
policy_updates: 0 # trained argmax students before policies are deleted
policy_threshold: 0.15 # difference to others

# Random Search
random_search: False
random_epochs_half: 25
random_iter: 50

# Replay memory
replay_mem: True
replay_batch: 10
replay_cap: 200
replay_thres: 0.8 # min top1 acc. to append # if ntu --> 0.8; kinetics 0.25

# Early stop # for ntu 6, 0.5, 5; for kinetics 6, 0.2, 5
early_stop: True
early_stop_epoch: 6
early_stop_acc: 0.4
early_stop_no_impr: 5

# PROXY Learning settings
proxy_mode: False
proxy_dir: ""

# Bootstrap test - give indicies for arch and hyper space
bootstrap: False
bootstrap_iter: 1
bootstrap_alpha: 5.0 # 100-alpha --> 95% CI
bootstrap_retrain: True
# bootstrap_path: "./logs/bootstrap_xsub60/2023-11-01 13-02-15/argmax_9999_relu6/student_model_9999.pth.tar"
# bootstrap_arch: [0, 2, 2, 1, 2, 0, 1, 2, 0, 1, 1, 1, 0, 0, 2, 1, 0, 0]
# bootstrap_hyper: [1, 0, 2, 0, 1]

bootstrap_arch: [3, 2, 3, 3, 0, 1, 0, 2, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0]
bootstrap_hyper: [2, 2, 0, 0, 0]
bootstrap_path: "./logs/JVBA_test_xview60/2023-10-24 16-59-11/argmax_9999_relu6/student_model_9999.pth.tar"
# bootstrap_arch: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
# bootstrap_hyper: [0, 0, 0, 0, 0]
# bootstrap_path: "./logs/bootstrap_xview60/2023-10-16 12-15-05/argmax_9999_relu6/student_model_9999.pth.tar"

# controller settings
controller_lr: 0.001
controller_dir: "/controller_weights/"

# fixed optimizer settings
optimizer_args:
  SGD:
    momentum: 0.9
    nesterov: True
  Adam:
    betas: [0.9,0.99]
    amsgrad: True
  RMSprop:
    centered: True
  AdamW:
    amsgrad: True

# lr scheduler settings
# might increase this
lr_scheduler: True
sched_args:
  warm_up: 10
  start_factor: 0.25
  step_lr: [30, 50, 60, 65, 70]
  gamma: 0.5

# Architect Search Space OLD -> used in AutoGCN
arch:
  # common
  init_lay:       [64, 128, 156, 195, 256] # big [156, 195, 256, 320] # small [64, 128, 156, 195, 256]
  act:            ["relu", "relu6", "hardswish", "swish"]
  att_lay:        ["stja", "ca", "fa", "ja", "pa"]
  conv_lay:       ["Basic", "Bottleneck", "Sep", "SG", "V3", "Shuffle"]
  drop_prob:      [0.15, 0.2, 0.25, 0.3]
  multi:          [False]
  expand_ratio:   [1, 1.5, 2]
  reduct_ratio:   [1, 1.5, 2]
  # input stream
  blocks_in:      [1, 2, 3] # big [2, 3, 4]  # small [1, 2, 3]
  depth_in:       [1, 2, 3] # big [3, 4, 5] # small [1, 2 ,3]
  stride_in:      [1, 2, 3]
  scale_in:       [0.4, 0.6, 0.8, 1, 1.1, 1.2]
  temp_win_in:    [3, 5, 7]
  graph_dist_in:  [2, 3, 4]

  # reduct_ratio_in: [ 1.225, 1.25, 1.275, 1.3, 1.325, 1.35 ] # highest ES 1.35
  # main stream
  blocks_main:      [1, 2, 3]  # big [5, 6, 7, 8] # small [3, 4, 5, 6]
  depth_main:       [1, 2, 3]  # big [3, 4, 5] # small [1, 2, 3, 4]
  stride_main:      [1, 2, 3]
  scale_main:       [0.95, 1, 1.1, 1.2, 1.3]
  temp_win_main:    [3, 5, 7]
  graph_dist_main:  [7, 9, 11]

# Architect Search Space NEW
arch_2:
  # common
  init_lay:       [64, 128, 256] # big [156, 195, 256, 320] # small [64, 128, 156, 195, 256]
  act:            ["relu", "relu6", "hardswish", "swish"]
  att_lay:        ["stja", "ca", "fa", "ja", "pa"]
  conv_lay:       ["Basic", "Bottleneck", "Sep", "SG", "V3", "Shuffle"]
  drop_prob:      [0.15, 0.2, 0.3]
  multi:          [False]
  expand_ratio:   [1, 1.5, 2]
  reduct_ratio:   [1, 1.5, 2]

  # input stream
  blocks_in:      [1, 2]
  depth_in:       [1, 2]
  stride_in:      [1, 2, 3]
  scale_in:       [0.7, 0.8, 0.9, 0.95]
  temp_win_in:    [3, 5, 7]
  graph_dist_in:  [1, 2, 3]

  # main stream
  blocks_main:      [1, 2, 3]
  depth_main:       [1, 2, 3]
  stride_main:      [1, 2, 3]
  scale_main:       [1.2, 1.25, 1.3]
  temp_win_main:    [3, 5, 7]
  graph_dist_main:  [1, 2, 3]

# Hyperparamter search space -common
hyper:
  lr:           [0.1, 0.05, 0.01]
  optimizers:   ['SGD', 'Adam', 'AdamW']
  weight_decay: [0.0, 0.01, 0.001, 0.0001]
  momentum:     [0.5, 0.9, 0.99]
  batch_size:   [8, 16, 24]

# --------------------------------------------- Debug settings ---------------------------------------------------
debug: False
debug_argmax_epoch: 1
debug_train_epochs: 1
debug_warmup_rollouts: 5
debug_rollouts: 5
debug_load_small_set: True

# Debug SP old
dev:
  blocks_in:    [2]
  depth_in:     [2]
  stride_in:    [3]
  blocks_main:  [2]
  depth_main:   [3]
  stride_main:  [2]
  temp_win:     [5]
  graph_dist:   [2]
  expand_ratio: [1.35]
  reduct_ratio: [1.2]
  scale_in:     [0.8]
  scale_main:   [2]
  act:          ["swish"]
  att_lay:      ['stja']
  conv_lay:     ["SG"] # "EpSep",
  init_lay:     [64]
  drop_prob:    [0.25]

# Debug SP new
dev_2:
  # Architect Search Space NEW

  # common
  init_lay: [ 64, 128, 256 ] # big [156, 195, 256, 320] # small [64, 128, 156, 195, 256]
  act: [ "relu", "relu6", "hardswish", "swish" ]
  att_lay: [ "stja", "ca", "fa", "ja", "pa" ]
  conv_lay: [ "Basic", "Bottleneck", "Sep", "SG", "V3", "Shuffle" ]
  drop_prob: [ 0.15, 0.2, 0.3 ]
  multi: [ False ]
  expand_ratio: [ 1, 1.5, 2 ]
  reduct_ratio: [ 1, 1.5, 2 ]

  # input stream
  blocks_in: [ 1, 2 ]
  depth_in: [ 1, 2 ]
  stride_in: [ 1, 2, 3 ]
  scale_in: [ 0.8, 0.9, 1, 1.1, 1.2 ]
  temp_win_in: [ 3, 5, 7 ]
  graph_dist_in: [ 1, 2, 3 ]

  # main stream
  blocks_main: [ 1, 2, 3 ]
  depth_main: [ 1, 2, 3 ]
  stride_main: [ 1, 2, 3 ]
  scale_main: [ 1, 1.1, 1.2, 1.3 ]
  temp_win_main: [ 3, 5, 7 ]
  graph_dist_main: [ 1, 2, 3 ]

# Hyperparamter search space -common
hyper_dev:
  lr:           [0.1, 0.05, 0.01]
  optimizers:   ['SGD', 'Adam', 'AdamW']
  weight_decay: [0.0, 0.01, 0.001, 0.0001]
  momentum:     [0.5, 0.9, 0.99]
  batch_size:   [8, 16, 24]